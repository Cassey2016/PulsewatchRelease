{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doh16101/anaconda3/envs/CS330_torch/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_model_idx 03\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[166825   5023   8053]\n",
      " [   241  22014   2300]\n",
      " [  1390   2852   8797]]\n",
      "TP [166825.  22014.   8797.]\n",
      "FN [13076.  2541.  4242.]\n",
      "micro_lower_bound 0.9789060598389742 micro_upper_bound 0.9789313493053761\n",
      "macro_lower_bound 0.9583617412204993 macro_upper_bound 0.958415160290333\n",
      "str_model_idx 04\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[160659  12221   7021]\n",
      " [   540  20033   3982]\n",
      " [  1494   3088   8457]]\n",
      "TP [160659.  20033.   8457.]\n",
      "FN [19242.  4522.  4582.]\n",
      "micro_lower_bound 0.9543424250424714 micro_upper_bound 0.9543753761159395\n",
      "macro_lower_bound 0.9383716804844981 macro_upper_bound 0.9384281076860351\n",
      "str_model_idx 05\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[168002   2472   9427]\n",
      " [   354  22465   1736]\n",
      " [  1760   2041   9238]]\n",
      "TP [168002.  22465.   9238.]\n",
      "FN [11899.  2090.  3801.]\n",
      "micro_lower_bound 0.9811043210905362 micro_upper_bound 0.9811205453516412\n",
      "macro_lower_bound 0.9514144373489178 macro_upper_bound 0.9514794683590697\n",
      "str_model_idx 06\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[162812   2047  15042]\n",
      " [    63  23390   1102]\n",
      " [  1562   1511   9966]]\n",
      "TP [162812.  23390.   9966.]\n",
      "FN [17089.  1165.  3073.]\n",
      "micro_lower_bound 0.9731031437777885 micro_upper_bound 0.9731288999864909\n",
      "macro_lower_bound 0.9628625796656837 macro_upper_bound 0.9629163224803072\n",
      "str_model_idx 07\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[163641   3145  13115]\n",
      " [   128  23826    601]\n",
      " [  1697    794  10548]]\n",
      "TP [163641.  23826.  10548.]\n",
      "FN [16260.   729.  2491.]\n",
      "micro_lower_bound 0.9775729736260523 micro_upper_bound 0.977592792251094\n",
      "macro_lower_bound 0.9702820909162735 macro_upper_bound 0.9703329598567327\n",
      "str_model_idx 08\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[164932   2397  12572]\n",
      " [    69  23946    540]\n",
      " [  1366    783  10890]]\n",
      "TP [164932.  23946.  10890.]\n",
      "FN [14969.   609.  2149.]\n",
      "micro_lower_bound 0.9818970803249419 micro_upper_bound 0.9819203121467704\n",
      "macro_lower_bound 0.9768227179363208 macro_upper_bound 0.9768520537764339\n",
      "str_model_idx 09\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[168651   1730   9520]\n",
      " [   128  23738    689]\n",
      " [  1700   1112  10227]]\n",
      "TP [168651.  23738.  10227.]\n",
      "FN [11250.   817.  2812.]\n",
      "micro_lower_bound 0.9861263482940231 micro_upper_bound 0.9861414102170097\n",
      "macro_lower_bound 0.975113984129858 macro_upper_bound 0.9751487991893915\n",
      "str_model_idx 10\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[167357   2695   9849]\n",
      " [   141  23638    776]\n",
      " [  1607   1645   9787]]\n",
      "TP [167357.  23638.   9787.]\n",
      "FN [12544.   917.  3252.]\n",
      "micro_lower_bound 0.9764632090364008 micro_upper_bound 0.9764909016016196\n",
      "macro_lower_bound 0.9688697032701139 macro_upper_bound 0.9689154617300311\n",
      "str_model_idx 11\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[171311   2256   6334]\n",
      " [   215  23934    406]\n",
      " [  2723   1332   8984]]\n",
      "TP [171311.  23934.   8984.]\n",
      "FN [8590.  621. 4055.]\n",
      "micro_lower_bound 0.9834576683282864 micro_upper_bound 0.9834776921307611\n",
      "macro_lower_bound 0.9714031868266653 macro_upper_bound 0.9714429271906231\n",
      "str_model_idx 12\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[169100   1854   8947]\n",
      " [   162  23739    654]\n",
      " [  2079   1070   9890]]\n",
      "TP [169100.  23739.   9890.]\n",
      "FN [10801.   816.  3149.]\n",
      "micro_lower_bound 0.983002125018742 micro_upper_bound 0.9830208477937908\n",
      "macro_lower_bound 0.9719543279805909 macro_upper_bound 0.9719965129120935\n",
      "str_model_idx 18\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[175535   2056   2310]\n",
      " [   785  22152   1618]\n",
      " [  2506   2274   8259]]\n",
      "TP [175535.  22152.   8259.]\n",
      "FN [4366. 2403. 4780.]\n",
      "micro_lower_bound 0.988927839203692 micro_upper_bound 0.9889417794995274\n",
      "macro_lower_bound 0.9581944357379719 macro_upper_bound 0.9582550548920222\n",
      "str_model_idx 19\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[173340   2419   4142]\n",
      " [   148  23968    439]\n",
      " [  2910    829   9300]]\n",
      "TP [173340.  23968.   9300.]\n",
      "FN [6561.  587. 3739.]\n",
      "micro_lower_bound 0.9923753235807863 micro_upper_bound 0.9923874512352678\n",
      "macro_lower_bound 0.9809221897372121 macro_upper_bound 0.9809544570604036\n",
      "str_model_idx 20\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[172009   1585   6307]\n",
      " [   377  21905   2273]\n",
      " [  2883   2407   7749]]\n",
      "TP [172009.  21905.   7749.]\n",
      "FN [7892. 2650. 5290.]\n",
      "micro_lower_bound 0.9871867424553931 micro_upper_bound 0.9872008346408268\n",
      "macro_lower_bound 0.958539917957581 macro_upper_bound 0.9586008656251104\n",
      "str_model_idx 21\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[162073   4022  13806]\n",
      " [   123  22992   1440]\n",
      " [  1905   1872   9262]]\n",
      "TP [162073.  22992.   9262.]\n",
      "FN [17828.  1563.  3777.]\n",
      "micro_lower_bound 0.9688400172600709 micro_upper_bound 0.9688700961988175\n",
      "macro_lower_bound 0.9590790327806544 macro_upper_bound 0.9591333918893328\n",
      "str_model_idx 22\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[164376   3281  12244]\n",
      " [  1011  22139   1405]\n",
      " [  1561   1898   9580]]\n",
      "TP [164376.  22139.   9580.]\n",
      "FN [15525.  2416.  3459.]\n",
      "micro_lower_bound 0.9763731214658707 micro_upper_bound 0.9763953817692355\n",
      "macro_lower_bound 0.9528509820307721 macro_upper_bound 0.9529203566349487\n",
      "str_model_idx 23\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[166194   3609  10098]\n",
      " [   478  23019   1058]\n",
      " [  2004   1648   9387]]\n",
      "TP [166194.  23019.   9387.]\n",
      "FN [13707.  1536.  3652.]\n",
      "micro_lower_bound 0.9810191336226698 micro_upper_bound 0.9810373648120734\n",
      "macro_lower_bound 0.9634994933828276 macro_upper_bound 0.9635555088761146\n",
      "str_model_idx 24\n",
      "Inside Linux\n",
      "Not inside Colab\n",
      "[[161955   2866  15080]\n",
      " [   136  23550    869]\n",
      " [  1444    906  10689]]\n",
      "TP [161955.  23550.  10689.]\n",
      "FN [17946.  1005.  2350.]\n",
      "micro_lower_bound 0.97735990272607 micro_upper_bound 0.9773782048893233\n",
      "macro_lower_bound 0.9717817840805869 macro_upper_bound 0.9718162576965624\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate the micro-AUROC from each fold plus the remaining NSR, and then average them.\n",
    "Copied from:\n",
    "/mnt/r/ENGR_Chon/Dong/Github_private/Pulsewatch_labeling/DeepBeat/experiments/try_07_eval_models/main_02_fold_1_2.py\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "import itertools\n",
    "import pathlib\n",
    "import numpy as np\n",
    "# === Start of path and model name for all models. ===\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # I only add this for pandas dataframe groupby warning. You should remove it in the future. \n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# For 1D PPG aug5k:\n",
    "# path_ckpt = r'/mnt/r/ENGR_Chon/Dong/Python_generated_results/deep_learning_2023/y_pred_2024_07_29_aug5k/TestRNNGRU_aug5k_PPG_HR_ACC_rescaleHR'\n",
    "# file_date = '20240728'\n",
    "# model_name = '1D_PPG_aug5k_HR_ACC_rescaleHR'\n",
    "sys.path.append('/mnt/r/ENGR_Chon/Dong/Github_private/Pulsewatch_labeling/DeepBeat/experiments/try_07_eval_models')\n",
    "import my_model_names\n",
    "# list_str_model_idx = ['01','02','03','04','05','06','07','08','09','10','11','12','18','19','20','21','22','23','24']\n",
    "list_str_model_idx = ['03','04','05','06','07','08','09','10','11','12','18','19','20','21','22','23','24']\n",
    "for str_model_idx in list_str_model_idx:\n",
    "# if True:\n",
    "    # str_model_idx = '10'\n",
    "    print('str_model_idx',str_model_idx)\n",
    "    path_ckpt, file_date, model_name = my_model_names.my_model_names(str_model_idx)\n",
    "    # === End of path and model names. ====\n",
    "\n",
    "    flag_linux = True\n",
    "    flag_Colab = False\n",
    "    # Append the directory to your python path using sys\n",
    "    if flag_linux:\n",
    "        print('Inside Linux')\n",
    "        if flag_Colab:\n",
    "            print('Inside Colab')\n",
    "            # For 'my_pathdef'\n",
    "        else:\n",
    "            print('Not inside Colab')\n",
    "            # For 'my_cfmatrix'\n",
    "            sys.path.append('/mnt/r/ENGR_Chon/Dong/Github_private/Pulsewatch_labeling/DeepBeat/utils')\n",
    "            import pretty_errors\n",
    "\n",
    "    import my_cfmatrix\n",
    "\n",
    "    # ====\n",
    "    if str_model_idx == '01' or str_model_idx == '02':\n",
    "        # TensorFlow model, so output saved in csv format.\n",
    "        if str_model_idx == '01':\n",
    "            filename_fold_1 = 'test_01_tfs_mm_fold_1.csv'\n",
    "            filename_fold_2 = 'test_01_tfs_mm_fold_2.csv'\n",
    "        else:\n",
    "            filename_fold_1 = 'test_02_poin_mm_fold_1.csv'\n",
    "            filename_fold_2 = 'test_02_poin_mm_fold_2.csv'\n",
    "\n",
    "        df_fold_1 = pd.read_csv(os.path.join(path_ckpt,filename_fold_1))\n",
    "        df_fold_2 = pd.read_csv(os.path.join(path_ckpt,filename_fold_2))\n",
    "\n",
    "        print('df_fold_1.shape',df_fold_1.shape)\n",
    "        print('df_fold_2.shape',df_fold_2.shape)\n",
    "        df_fold_1_2_tfs = df_fold_1.merge(df_fold_2, how='outer', on='table_file_name', indicator = True)\n",
    "        # Fold-1 and 2 combined results:\n",
    "        # df_fold_1_results = df_fold_1_2_tfs.loc[(df_fold_1_2_tfs['_merge'] == 'left_only')]\n",
    "        # df_fold_2_results = df_fold_1_2_tfs.loc[(df_fold_1_2_tfs['_merge'] == 'right_only')]\n",
    "\n",
    "        y_pred_1 = df_fold_1_2_tfs['y_pred_x'].to_list()\n",
    "        y_true_1 = df_fold_1_2_tfs['y_true_x'].to_list()\n",
    "        y_pred_2 = df_fold_1_2_tfs['y_pred_y'].to_list()\n",
    "        y_true_2 = df_fold_1_2_tfs['y_true_y'].to_list()\n",
    "\n",
    "        df_fold_1 = pd.DataFrame({'table_file_name':df_fold_1_2_tfs['table_file_name'].to_list(),'y_pred':y_pred_1,'y_true':y_true_1})\n",
    "        df_fold_2 = pd.DataFrame({'table_file_name':df_fold_1_2_tfs['table_file_name'].to_list(),'y_pred':y_pred_2,'y_true':y_true_2})\n",
    "\n",
    "        # Remove SVT class:\n",
    "        df_fold_1 = df_fold_1.loc[(df_fold_1['y_true'] == 0) | \\\n",
    "                            (df_fold_1['y_true'] == 1) | \\\n",
    "                            (df_fold_1['y_true'] == 2)] # Dong, 07/01/2024.\n",
    "        df_fold_2 = df_fold_2.loc[(df_fold_2['y_true'] == 0) | \\\n",
    "                            (df_fold_2['y_true'] == 1) | \\\n",
    "                            (df_fold_2['y_true'] == 2)] # Dong, 07/01/2024.\n",
    "        # Since 'y_pred_prob_0', 'y_pred_prob_1', 'y_pred_prob_2' are not in the table, I will fake one until I have them.\n",
    "        df_fold_1.insert(3,'y_pred_prob_0',np.zeros((df_fold_1.shape[0],),dtype=float))\n",
    "        df_fold_1.insert(3,'y_pred_prob_1',np.zeros((df_fold_1.shape[0],),dtype=float))\n",
    "        df_fold_1.insert(3,'y_pred_prob_2',np.zeros((df_fold_1.shape[0],),dtype=float))\n",
    "        df_fold_2.insert(3,'y_pred_prob_0',np.zeros((df_fold_2.shape[0],),dtype=float))\n",
    "        df_fold_2.insert(3,'y_pred_prob_1',np.zeros((df_fold_2.shape[0],),dtype=float))\n",
    "        df_fold_2.insert(3,'y_pred_prob_2',np.zeros((df_fold_2.shape[0],),dtype=float))\n",
    "\n",
    "        print('df_fold_1[y_true] == 3',df_fold_1.loc[df_fold_1['y_true'] == 3])\n",
    "    elif str_model_idx == '18' or str_model_idx == '19':\n",
    "        fold_name = 'fold_1'\n",
    "        filename_ckpt = 'test_02_Liu_JAHA_2022_the_other_fold_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_1_fold = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        fold_name = 'fold_2'\n",
    "        filename_ckpt = 'test_02_Liu_JAHA_2022_the_other_fold_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_2_fold = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        fold_name = 'fold_1'\n",
    "        filename_ckpt = 'test_03_Liu_JAHA_2022_remain_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_1_NSR = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        fold_name = 'fold_2'\n",
    "        filename_ckpt = 'test_03_Liu_JAHA_2022_remain_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_2_NSR = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        path_output = '/'.join(path_ckpt.split('/')[:-1])\n",
    "        df_fold_1 = pd.concat([df_fold_1_fold, df_fold_1_NSR], ignore_index=True, sort=False)\n",
    "        df_fold_2 = pd.concat([df_fold_2_fold, df_fold_2_NSR], ignore_index=True, sort=False)\n",
    "        df_fold_1_2_tfs = df_fold_1.merge(df_fold_2, how='outer', on='table_file_name', indicator = True)\n",
    "    elif str_model_idx == '20':\n",
    "        # Darren said on 09/28/2024 that he has same files like I have in\n",
    "        # R:\\ENGR_Chon\\Darren\\Honors_Thesis\\saves_tfs\\cassey_fold_1_trained\\output_files\n",
    "        y_pred_filename_fold_1 = 'predictions_fold_1_other_fold_test_set.csv'\n",
    "        y_pred_filename_fold_2 = 'predictions_fold_2_other_fold_test_set.csv'\n",
    "\n",
    "        y_true_filename_fold_1 = 'labels_fold_1_other_fold_test_set.csv'\n",
    "        y_true_filename_fold_2 = 'labels_fold_2_other_fold_test_set.csv'\n",
    "\n",
    "        pred_prob_filename_fold_1 = 'prediction_proba_fold_1_other_fold_test_set.csv'\n",
    "        pred_prob_filename_fold_2 = 'prediction_proba_fold_2_other_fold_test_set.csv'\n",
    "\n",
    "        y_pred_fold_1 = pd.read_csv(os.path.join(path_ckpt,y_pred_filename_fold_1))\n",
    "        y_pred_fold_2 = pd.read_csv(os.path.join(path_ckpt,y_pred_filename_fold_2))\n",
    "        y_true_fold_1 = pd.read_csv(os.path.join(path_ckpt,y_true_filename_fold_1))\n",
    "        y_true_fold_2 = pd.read_csv(os.path.join(path_ckpt,y_true_filename_fold_2))\n",
    "        pred_prob_fold_1 = pd.read_csv(os.path.join(path_ckpt,pred_prob_filename_fold_1))\n",
    "        pred_prob_fold_2 = pd.read_csv(os.path.join(path_ckpt,pred_prob_filename_fold_2))\n",
    "\n",
    "        # print('y_pred_fold_1.columns',y_pred_fold_1.columns) # 'predictions'\n",
    "        # print('y_true_fold_1.columns',y_true_fold_1.columns) # 'labels'\n",
    "        # print('pred_prob_fold_1.columns',pred_prob_fold_1.columns) # '0', '1', '2'\n",
    "\n",
    "        df_fold_1_fold = pd.DataFrame({'y_pred':y_pred_fold_1['predictions'].to_list(),\n",
    "                                  'y_true':y_true_fold_1['labels'].to_list(),\n",
    "                                  'y_pred_prob_0':pred_prob_fold_1['0'].to_list(),\n",
    "                                  'y_pred_prob_1':pred_prob_fold_1['1'].to_list(),\n",
    "                                  'y_pred_prob_2':pred_prob_fold_1['2'].to_list()})\n",
    "        \n",
    "        # print('df_fold_1',df_fold_1)\n",
    "\n",
    "        df_fold_2_fold = pd.DataFrame({'y_pred':y_pred_fold_2['predictions'].to_list(),\n",
    "                                  'y_true':y_true_fold_2['labels'].to_list(),\n",
    "                                  'y_pred_prob_0':pred_prob_fold_2['0'].to_list(),\n",
    "                                  'y_pred_prob_1':pred_prob_fold_2['1'].to_list(),\n",
    "                                  'y_pred_prob_2':pred_prob_fold_2['2'].to_list()})\n",
    "        \n",
    "        # print('df_fold_2',df_fold_2)\n",
    "        y_pred_filename_fold_1 = 'predictions_fold_1_remove_both_folds.csv'\n",
    "        y_pred_filename_fold_2 = 'predictions_fold_2_remove_both_folds.csv'\n",
    "\n",
    "        y_true_filename_fold_1 = 'labels_fold_1_remove_both_folds.csv'\n",
    "        y_true_filename_fold_2 = 'labels_fold_2_remove_both_folds.csv'\n",
    "\n",
    "        pred_prob_filename_fold_1 = 'prediction_proba_fold_1_remove_both_folds.csv'\n",
    "        pred_prob_filename_fold_2 = 'prediction_proba_fold_2_remove_both_folds.csv'\n",
    "\n",
    "        y_pred_fold_1 = pd.read_csv(os.path.join(path_ckpt,y_pred_filename_fold_1))\n",
    "        y_pred_fold_2 = pd.read_csv(os.path.join(path_ckpt,y_pred_filename_fold_2))\n",
    "        y_true_fold_1 = pd.read_csv(os.path.join(path_ckpt,y_true_filename_fold_1))\n",
    "        y_true_fold_2 = pd.read_csv(os.path.join(path_ckpt,y_true_filename_fold_2))\n",
    "        pred_prob_fold_1 = pd.read_csv(os.path.join(path_ckpt,pred_prob_filename_fold_1))\n",
    "        pred_prob_fold_2 = pd.read_csv(os.path.join(path_ckpt,pred_prob_filename_fold_2))\n",
    "\n",
    "        # print('y_pred_fold_1.columns',y_pred_fold_1.columns) # 'predictions'\n",
    "        # print('y_true_fold_1.columns',y_true_fold_1.columns) # 'labels'\n",
    "        # print('pred_prob_fold_1.columns',pred_prob_fold_1.columns) # '0', '1', '2'\n",
    "\n",
    "        df_fold_1_NSR = pd.DataFrame({'y_pred':y_pred_fold_1['predictions'].to_list(),\n",
    "                                  'y_true':y_true_fold_1['labels'].to_list(),\n",
    "                                  'y_pred_prob_0':pred_prob_fold_1['0'].to_list(),\n",
    "                                  'y_pred_prob_1':pred_prob_fold_1['1'].to_list(),\n",
    "                                  'y_pred_prob_2':pred_prob_fold_1['2'].to_list()})\n",
    "        \n",
    "        # print('df_fold_1',df_fold_1)\n",
    "\n",
    "        df_fold_2_NSR = pd.DataFrame({'y_pred':y_pred_fold_2['predictions'].to_list(),\n",
    "                                  'y_true':y_true_fold_2['labels'].to_list(),\n",
    "                                  'y_pred_prob_0':pred_prob_fold_2['0'].to_list(),\n",
    "                                  'y_pred_prob_1':pred_prob_fold_2['1'].to_list(),\n",
    "                                  'y_pred_prob_2':pred_prob_fold_2['2'].to_list()})\n",
    "        \n",
    "        # print('df_fold_2',df_fold_2)\n",
    "        df_fold_1 = pd.concat([df_fold_1_fold, df_fold_1_NSR], ignore_index=True, sort=False)\n",
    "        df_fold_2 = pd.concat([df_fold_2_fold, df_fold_2_NSR], ignore_index=True, sort=False)\n",
    "        # df_fold_1_2_tfs = df_fold_1.merge(df_fold_2, how='outer', on='table_file_name', indicator = True)\n",
    "    else:\n",
    "        fold_name = 'fold_1'\n",
    "        filename_ckpt = 'test_02_the_other_fold_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_1_fold = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        fold_name = 'fold_2'\n",
    "        filename_ckpt = 'test_02_the_other_fold_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_2_fold = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        path_output = '/'.join(path_ckpt.split('/')[:-1])\n",
    "\n",
    "        fold_name = 'fold_1'\n",
    "        filename_ckpt = 'test_03_remain_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_1_NSR = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        fold_name = 'fold_2'\n",
    "        filename_ckpt = 'test_03_remain_train_RNN_GRU_'+file_date+'_'+fold_name+'.pt'\n",
    "        df_fold_2_NSR = my_cfmatrix.my_load_pt_results(path_ckpt, filename_ckpt)\n",
    "\n",
    "        path_output = '/'.join(path_ckpt.split('/')[:-1])\n",
    "\n",
    "        df_fold_1 = pd.concat([df_fold_1_fold, df_fold_1_NSR], ignore_index=True, sort=False)\n",
    "        df_fold_2 = pd.concat([df_fold_2_fold, df_fold_2_NSR], ignore_index=True, sort=False)\n",
    "\n",
    "    # print('model',str_model_idx,'df_fold_1.shape',df_fold_1.shape,'df_fold_2.shape',df_fold_2.shape)\n",
    "    df_all = pd.concat([df_fold_1, df_fold_2], ignore_index=True, sort=False)\n",
    "    # Calculate Sensitivity (TPR), Specificity (TNR), Precision (PPV), NPV, FPR, FNR, FDR, Accuracy (ACC).\n",
    "    dict_metrics_all = my_cfmatrix.my_average_none_metrics(y_true = df_all['y_true'], y_pred = df_all['y_pred'])\n",
    "\n",
    "    rng_seed = 42\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    n_bootstraps = 1000\n",
    "    micro_aucs = []\n",
    "    macro_aucs = []\n",
    "    # Calculate the AUROC.\n",
    "    n_classes = 3\n",
    "    my_class_names = {0: 'NSR', 1: 'AF', 2: 'PAC/PVC'}\n",
    "    # Get the class ratio for the entire DataFrame\n",
    "    from functools import partial\n",
    "    vc_norm = partial(pd.Series.value_counts, normalize=True)\n",
    "    # print('df_all y_true value_counts')\n",
    "    # print(df_all['y_true'].agg([pd.Series.value_counts, vc_norm]))\n",
    "\n",
    "    # print(df_value_counts)\n",
    "    for i in range(n_bootstraps):\n",
    "        \n",
    "        # bootstrap by sampling with replacement on the prediction indices\n",
    "        sample_n = rng.randint(0, df_all.shape[0], size=1)\n",
    "\n",
    "        # sample_n = len(indices)\n",
    "\n",
    "        # df_all_sample = df_all.sample(n=sample_n, random_state=rng_seed)\n",
    "        # df_all_sample = df_all.groupby('y_true',group_keys = False).apply(lambda x: x.sample(n=sample_n, frac=None, replace=True, random_state=rng_seed),include_groups = True)\n",
    "        df_all_sample = df_all.groupby('y_true', group_keys=False).apply(lambda x: x.sample(int(np.rint(sample_n*len(x)/len(df_all))))).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # print(f'In CI {i}/{n_bootstraps}, len(df_all_sample)={len(df_all_sample)}')\n",
    "        unique_class = len(df_all_sample['y_true'].unique())#len(np.unique(y_true[indices]))\n",
    "        if unique_class < n_classes:\n",
    "            # We need at least one positive and one negative sample for ROC AUC\n",
    "            # to be defined: reject the sample\n",
    "            continue\n",
    "\n",
    "        # Get the ratio of class for the sampled DataFrame\n",
    "        vc_norm = partial(pd.Series.value_counts, normalize=True)\n",
    "        # print('df_all_sample y_true value_counts')\n",
    "        # print(df_all_sample['y_true'].agg([pd.Series.value_counts, vc_norm]))\n",
    "\n",
    "        test_name = 'AUROC_all_pulsewatch_subject_independent_test_CI'\n",
    "        shorted_test_name = 'CI'\n",
    "        path_output = os.path.join(r'/mnt/r/ENGR_Chon/Dong/Python_generated_results/deep_learning_2023/analysis_2024_07_30',test_name)\n",
    "        path_output_fig = os.path.join(path_output,'plots')\n",
    "        pathlib.Path(path_output_fig).mkdir(parents=True, exist_ok=True)\n",
    "        micro_roc_auc_ovr, macro_roc_auc_ovr = my_cfmatrix.my_auroc_cal_plot(df_all_sample, n_classes, my_class_names, path_output_fig, model_name, test_name, str_model_idx, fold_name='all')\n",
    "        micro_aucs.append(micro_roc_auc_ovr)\n",
    "        macro_aucs.append(macro_roc_auc_ovr)\n",
    "    \n",
    "    # Calculate the AUROC condifence interval.\n",
    "    alpha = 0.05\n",
    "    micro_lower_bound = np.percentile(micro_aucs, (1 - alpha) / 2 * 100)\n",
    "    micro_upper_bound = np.percentile(micro_aucs, (1 + alpha) / 2 * 100)\n",
    "\n",
    "    macro_lower_bound = np.percentile(macro_aucs, (1 - alpha) / 2 * 100)\n",
    "    macro_upper_bound = np.percentile(macro_aucs, (1 + alpha) / 2 * 100)\n",
    "\n",
    "    print('micro_lower_bound',micro_lower_bound,'micro_upper_bound',micro_upper_bound)\n",
    "    print('macro_lower_bound',macro_lower_bound,'macro_upper_bound',macro_upper_bound)\n",
    "    \n",
    "    # Add new key value pair\n",
    "    dict_metrics_all['micro_auroc'] = np.mean(micro_aucs)\n",
    "    dict_metrics_all['macro_auroc'] = np.mean(macro_aucs)\n",
    "    dict_metrics_all['micro_lower_bound'] = micro_lower_bound\n",
    "    dict_metrics_all['micro_upper_bound'] = micro_upper_bound\n",
    "    dict_metrics_all['macro_lower_bound'] = macro_lower_bound\n",
    "    dict_metrics_all['macro_upper_bound'] = macro_upper_bound\n",
    "\n",
    "    # df_metrics = pd.DataFrame(dict_metrics_avg.items(),columns=dict_metrics_avg.keys())\n",
    "    df_metrics = pd.DataFrame.from_dict(dict_metrics_all, orient='columns').reset_index()\n",
    "    df_metrics.to_csv(os.path.join(path_output,str_model_idx+'_'+model_name+'_'+shorted_test_name+'.csv'),header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_aucs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS330_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
